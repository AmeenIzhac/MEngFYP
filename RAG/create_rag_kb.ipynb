{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5IP-wzFv5jX"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pinecone-client sentence-transformers langchain-openai datasets openai groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1uiGa0DG4wZ"
      },
      "outputs": [],
      "source": [
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "pc = Pinecone(api_key='INSERT_PINECONE_API_KEY_HERE')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kko-wq0Us6D"
      },
      "outputs": [],
      "source": [
        "index_name = \"anatomy-book-b\"\n",
        "\n",
        "if index_name not in pc.list_indexes().names():\n",
        "  pc.create_index(\n",
        "      name=index_name,\n",
        "      dimension=1536,\n",
        "      metric=\"cosine\",\n",
        "      spec=ServerlessSpec(\n",
        "          cloud='aws',\n",
        "          region='us-east-1'\n",
        "      )\n",
        "  )\n",
        "\n",
        "index = pc.Index(index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Upt_cr20G841"
      },
      "outputs": [],
      "source": [
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ys16bnn7JdEX"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "embed_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\", openai_api_key=\"INSERT_OPEN_API_KEY_HERE\")\n",
        "\n",
        "def get_relevant_context(text, k=1):\n",
        "  embeds = embed_model.embed_documents([text])\n",
        "  results_1 = index.query(\n",
        "      vector=embeds,\n",
        "      top_k=k,\n",
        "      include_metadata=True\n",
        "  )\n",
        "\n",
        "  results = []\n",
        "\n",
        "  for result in results_1[\"matches\"]:\n",
        "    results.append(result[\"metadata\"][\"text\"])\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHziIbKovR4I"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"openlifescienceai/medmcqa\", split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Im1d8s9ya9q"
      },
      "outputs": [],
      "source": [
        "medmcqa_texts = []\n",
        "for sample in dataset:\n",
        "  text = f'''{sample[\"question\"]} (A) {sample[\"opa\"]}, (B) {sample[\"opb\"]} (C) {sample[\"opc\"]} (D) {sample[\"opd\"]}. Answer with explanation: {sample[\"exp\"]}'''\n",
        "  medmcqa_texts.append(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yultmp8K_ES0"
      },
      "outputs": [],
      "source": [
        "with open(\"anatomybook1.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    anatomy_book_text = file.read()\n",
        "\n",
        "anatomy_book_words = anatomy_book_text.split()\n",
        "\n",
        "anatomy_docs = []\n",
        "\n",
        "for i in range(0, len(anatomy_book_words), 100):\n",
        "\n",
        "  i_end = min(i + 100, len(anatomy_book_words))\n",
        "  new_doc1 = \" \".join(anatomy_book_words[i: i_end])\n",
        "  anatomy_docs.append(new_doc1)\n",
        "\n",
        "  if (i_end + 50 < len(anatomy_book_words)):\n",
        "    new_doc2 = \" \".join(anatomy_book_words[i + 50: i_end + 50])\n",
        "    anatomy_docs.append(new_doc2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmKTfIkhFdHT"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=\"INSERT_OPEN_API_KEY_HERE\")\n",
        "\n",
        "def prompt_gpt(prompt):\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You rewrite text in a way that is more informative and fill in missing information. You are not conversational i.e. you simply respond with the re written text and nothing else.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}]\n",
        "  )\n",
        "  return completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAA_kG343qe0",
        "outputId": "52b3d46c-dd42-469b-97e0-53fbffb50cae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4440/4440 [4:03:42<00:00,  3.29s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "instruction = \"The following is a piece of text scraped from an Anatomy text book. It may be containing missing information and start and end in the middle of a sentence. If the text speaks about a figure or an image, try to instead explain what it is mentioning in a way that does not require access to the image. Respond with a clean form of the information suitable for use as a document in a RAG anatomy knowledgebase: \"\n",
        "refined_docs = []\n",
        "\n",
        "for doc in tqdm(anatomy_docs):\n",
        "  refined_docs.append(prompt_gpt(instruction + doc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOFqa8BnV2JD",
        "outputId": "7e3ffc55-b244-4ecf-b448-824a7ff074b2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [01:48<00:00,  2.40s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "texts = refined_docs\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "for i in tqdm(range(0, len(texts), batch_size)):\n",
        "    i_end = min(len(texts), i+batch_size)\n",
        "    batch = texts[i:i_end]\n",
        "    ids = [\"anatomy-book-b-\" + str(i) for i in range(i, i_end)]\n",
        "    embeds = embed_model.embed_documents(batch)\n",
        "    metadata = [{'text': text} for text in batch]\n",
        "    index.upsert(vectors=zip(ids, embeds, metadata))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
